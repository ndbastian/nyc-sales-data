---
title: "Literature Review"
output: pdf_document
bibliography: bib/bibliography.bib
---

## How Has Economic Displacement Been Addressed in the Past?

Economic Displacement has been intertwined with the study of gentrification since shortly after the latter became academically relevant in the 1960's.  Gentrification was first popularized by Ruth Glass in 1964 to described the “gentry” in low income neighborhoods in London. Gentirifcation was originally understood as a "tool of revitilization for declining neighborhoods" [@Zuk2015], however, in 1979 Phillip Clay  made the distinction between two types of revitilization: "incumbent upgrading" and "gentrification", noting that Economic Displacement was the negative consequence of the latter [@Clay1979]. Today, the term has evolved to describe "a spatial organization and re-organiztion of human dwelling and activity" [@Zuk2015]. Specific to cities, gentrification is thought of as “the transformation of a working-class or vacant area of the central city into middle-class residential or commercial use” [@Lees2008].

Studies of gentrification and displacement generally take two approaches in the literature: supply-side and demand-side, or "the flows of capital versus flows of people to neighborhoods", respectively [@Zuk2015]. Supply side arguments for gentrification tend to focus on "private capital investment, public policies, and public investments" [@Zuk2015]. [@Smith1979] argued that the return of capital from the suburbs to the city drives gentrification. He describes a "political economy of capital flows into urban areas" [@Zuk2015] as largely responsible for both the positive and negative consequences of gentrification. Supply-side arguments have the advantage of being focused around public policy. Policies that have been linked to increased Economic Displacment have been, among others, automobile-oritented transportation infrastrucure spending and mortgage interest tax deductions for home owners  [@Dreier2004].

Living in poor neighborhoods negatively impacts residents by making them more prone to "participate in and be victims of criminal activity" and other poor socio-economic outcomes [@Zuk2015]. More recently, we have come to understand that Economic Displacement can be influenced "mostly by income inequality, in particular, higher compensation in the top quintile and the lack of jobs for the bottom quintile" [@Reardon2011]; [@Watson2009]. Inequality has become a highly visible topic in recent years, with critics pointing out that the concentration of wealth allows "certain households to sort themselves according to their preferences – and control local political processes that continue exclusion [@Reardon2011]. @Reardon2011 argues that "were income inequality to stop rising, the number of segregated neighborhoods would decline."

Many studies conclude that gentrification in most forms leads to exclusionary economic displacement, however, @Zuk2015 characterizes the results of many recent studies as "mixed, due in part to methodological shortcomings".





African American - White segregation has persisted in major metropolitan areas, especially in the Northeast and Midwest and a large share of minorities still live in neighborhoods with virtually no White residents (Logan 2013).

A theory of “place stratification” is a better fit, incorporating discriminating institutions that limit residential movement of African Americans into White neighborhoods, such as biased residential preferences among nonHispanic Whites and discrimination in the real estate market (Charles 2003; Krysan et al. 2009; Turner et al. 2013). 

Yet, for many at the lower end of the economic spectrum, stability means imprisonment: even though many families have left, researchers estimate that some 70% of families in today’s impoverished neighborhoods were living there in the 1970s as well (Sharkey 2012).

Scholars writing on the “geographies of opportunity” (Briggs 2005) argue that the spatial relationships between high quality housing, jobs, and schools structure social mobility. Patterns of urban development in the United States have resulted in uneven geographies of opportunity, in which low-income and families of color experience limited access to affordable housing, high quality schools, and good-paying jobs. 


## A Review of Mass Appraisal Techniques

Much of the research on predicting real estate values has been in service of creating mass appraisal models. Mass appraisal models share many characteristics with predictive machine learning model modeling. Mass appraisal models are data-driven, standardized methods that employ statistical testing [@Eckert1990].

[@Quintos2013]
Attempts to measure latent variables through a random effect regression model to predict income and expense of non-filers.  Difference between the Assessed Value and the Market Value.

New York City annually values commercial properties by the income approach. Commercial properties with an assessed value greater than $40,000 are required to file income and expense statements with the Department of Finance. Some of these required filers may apply for exclusion from filing or they may choose not to file and instead pay a penalty. There are also voluntary filers, who are not required to file but nevertheless submit statements. The filings received are used to formulate income and expense regression models. These models are used to develop comparable rental models and to formulate assessment guidelines based on location and physical characteristics.

For models of income and expense, however, we are not aware of a model in a random effects (panel data) framework—most likely due to the lack of property-level data of income and expense filings. 

[@Springer2017] Great Lit review in first chapter on the evolution of the Automated Valuation Model. Walks through all different kinds of spatial models: OLS, Heirarchichal, spatial lag, spatial error, etc. Explains COD (coeficient of dispersion). Dodd Frank Act implements financial regulatory reform after the financial crisis of 2008. In particular the title XIV subtitle F distinguishes appraisal process from automated valuation modelling, reorganizing both. In particular it was stressed how the role of valuation (appraisal) cannot be replaced by AVM. Our point of view is coherent with the Dodd Frank act (and Appraisal Methods and the Non-Agency Mortgage Crisis 29 thereby also Pugh’s view but not Woodward’s): automated valuation modelling is increasingly adaptable in describing real estate market behaviour without succeeding in replacing local information and human inspection in the valuation (appraisal) procedure. 

[@Koschinsky2012]
This is a recent and thorough discussion of parametric hedonic regression techniques. Some of the variables included are derived from nearby properties, similar to my technique, and these variables are found to be predictive. Methodology section (2) contains a brief but robust literature review of hedonic price modeling applied to real estate marginal willingness to pay (MWTP) for locational attributes. The basic hedonic model assumes that the utility of a household or an individual is a function of a composite good x; a vector of structural characteristics S; a vector of social and neighborhood characteristics N; and finally a vector of locational characteristics L. This study adds to a small body of existing literature that extends this research by addressing the valuation of a property’s locational attributes from a spatial perspective. 

In the model, for a spatial lag, they use a "We specify W as a queen contiguity weights matrix." The second set of locational attribute data represents a new way of measuring attributes of neighboring properties that is fully exogenous since it is derived from a different dataset than the sales data: It is based on structural characteristics of all residential properties built before 1997 that are not for sale but are within 1,000 feet of a 1997 sale. ... The variables included for neighboring properties within 1,000 feet of a sale are average age, poor condition (%), with electric heating source (strongly correlated with older age) (%), poor construction grade (1–5) (%), high construction grade (10–13) (%), and detached single-family homes (%). The spatial parameter lambda is positive and significant in all cases, i.e. the relation between a home’s price and the average price of its neighboring homes is characterized by positive spatial autocorrelation where, for instance, high-price homes are surrounded by houses with high prices

In short, for the data in this study locational characteristics are valued at least as much as (if not more) than important structural characteristics.

In this case the correct welfare measure should be the direct effect since there is a strong argument in the literature (e.g. Pace and Gilley 1998) that spatial autocorrelation in house prices is related to the practice of realtors, appraisers and home owners of using nearby comparable sales to determine the sales price of a property. Therefore it is to be expected that a house which is in a neighborhood where the sales price of recently sold houses is high will be higher than a similar house surrounded by houses recently sold at a low price. This will lead to spatial autocorrelation in house prices, but the origin for such autocorrelation is a pecuniary externality


[@Fotheringham2015]
Explores the use of GWR to forecast prices.Explores the combination of time-series forecasting (in the Holt-Winters tradition) to geogaphically weighted regression (GWR). GWR is a variation on OLS that allows for "adaptive bandwidths" of local data to be included, i.e., for each estimate, the number of data points included varies (optimized using CV). In addition, the data points are weighted according to distance. This is known as a "local" model

## Has Machine Learning Been Applied to this Problem Before?

[@Zuk2015]
It is arguably a “chaotic” process, that does not lend itself to binary or linear analysis (Beauregard 1986; Freeman 2006; L. Lees 1996)

[@Zuk2015]
Urban simulation models are guided by consumer decision-making, rather than the development decisions – flows of people rather than capital – and have neglected the role of race; thus they may not capture complex gentrification dynamics.

Presentation by researchers from the Urban Institute (Austin Turner and Snow 2001). Analyzing data for the DC area, they identified the following five leading indicators as predictive of future gentrification (defined as sales prices that are above the D.C. average) as low priced areas that are: 
1) adjacent to higher-priced areas, 
2) have good metro access, 
3) contain historic architecture,
4) have large housing units, and 
5) experience over 50% appreciation in sales prices between 1994 and 2000. 

Census tracts were scored for each indicator and then ranked according to the sum of indicators with a maximum value of 5.
(Note: Analysis done at the census-tract level)

(Chapple 2009). Chapple adopted Freeman’s (2005) definition of gentrifying neighborhoods as lowincome census tracts in central city locations in 1990 that by 2000 experienced housing appreciation and increased educational attainment above the 9-county regional average. 
(Note: Analysis done at the census-tract level)

(Pollack, Bluestone, and Billingham 2010). Analyzing 42 neighborhoods (block groups within ½ mile of a transit station) near rail stations in 12 metro areas across the United States, they studied changes between 1990 and 2000 for neighborhood socioeconomic and housing characteristics
(Note: Analysis done at the neighborhood level)

[@Schernthanner2016] Paper compares traditional linear regression techniques to more advnaced techniques such as krigging (stochastic interpolation) and random forrest; finds that more advanced techniques are sound and more accurate. The research findings indicate that the analysis results achieved by any of the new methods, ranging from stochastic interpolation to the “random forest” method of machine learning, are more valid than results obtained from traditional statistical methods

[@Guan2014] Uses three different approaches to defining comps, all using euclidean distance; a radius technique, a k-nearest neighbors technique using only distance and a k-nearest neighbors technique using all attributes. Interestingly, the location-only KNN neighborhood performed best, although by a very slim margin (potentially meaningless). The MRA [Multiple Regression Analysis] method, although widely used in mass appraisal, has been criticized for its inability to model data features typically found in real estate data. Common problems with MRA assessment of real estate properties are well known and they include nonlinear- ity, multicollinearity, and heteroscedasticity (Antipov and Pokryshevskaya 2012; Kilpatrick 2011; Mark and Goldberg 1988; Peterson and Flanagan 2009). In recent years, data mining methods have been proposed as an alternative, and have been tested with very mixed results.

[@Fu2014]
Prediction model for real estate in Beijin, China. They do a clustering, then do a rank-ordered prediction of investment returns segmented into categories: 4>3>2>1>0

While a number of estate appraisal methods have been devel- oped to value real property, the performances of these meth- ods have been limited by the traditional data sources for es- tate appraisal

the geographic dependencies of the value of an estate can be from the characteristics of its own neighborhood (individual), the values of its nearby estates (peer), and the prosperity of the affiliated latent business area (zone)

ClusRanking is able to exploit geographic individ- ual, peer, and zone dependencies in a probabilistic ranking model. Specifically, we first extract the geographic utility of estates from geography data, estimate the neighborhood popularity of estates by mining taxicab trajectory data, and model the influence of latent business areas via ClusRank- ing.

From related works: Recent works [8, 21] study the automated valuation models, which aggregate and ana- lyze physical characteristics and sales prices of comparable properties to provide property valuations


[@Rafiei2016]
Fascinating paper which employs a Restricted Boltzmann Machine (neural network with back propagation) to predicted the sale price of residential condos in Tehran, Iran. The paper focuses on computational efficiency. A non-mating genetic algorithm is used for dimensionality reduction. The paper concludes that two  primary strategies help in this regard: Sales which happened closer in time to a prediction are more important, and it also uses a learner to accelerate the recognition of important features. The paper compares this technique to several other common NN approaches and finds that while not necessarily the only way to get the best answer, it is definitely the fastest way to get to the best answer. The lit review sections walks through several recent and notable papers specifically on the topic of sales price prediction of real estate. There is also mention of a paper which characterizes a real estate market as supply inelastic which may be worth investigating further. 



[@Helbich2013]
This is a very recent paper which contains a brief but robust literature review in the introduction. Great quote: hedonic pricing models "can be improved in two ways: (a) Through novel estimation techniques (e.g. Brunauer et al., 2010; Koschinsky, Lozano-Gracia, & Piras, 2011) and (b) by ancillary structural, locational, and neighborhood variables on the basis of Geographic Information System (GIS) algorithms (e.g. Hamilton & Morgan, 2010)"

Let's follow up on the sources mentioned. I believe my micro-neighborhood technique falls into the "unique estimation" bucket, so it would be wise to position it that way


[@Kontrimasa2011]
Mass appraisal is commonly used to compute real estate tax. Study uses an n = 100 (very small) and compares accuracy of linear regression vs other ANN techniques like SVM. 


[@Dietzell2014]
This paper examines internet search query data provided by “Google Trends”, with respect to its ability to serve as a sentiment indicator and improve commercial real estate forecasting models for transactions and price indices. The empirical results show that all models augmented with Google data, combining both macro and search data, significantly outperform baseline models which abandon internet search data


[@Pivo2011]
Examines the effects of walkability on property values and investment returns. Use data from the National Council of Real Estate Investment Fiduciaries and Walk Score to examine the effects of walkability on the market value and investment returns of more than 4,200 office, apartment, retail and industrial properties from 2001 to 2008 in the United States. On a 100-point scale, a 10-point increase in walkability increased values by 1–9%, depending on property type. We also found that walkability was associated with lower cap rates and higher incomes, suggesting it has been favored in both the capital asset and building space markets


[@Park2015]
Machine learning applied to residential real estate price prediction. Developed a housing price prediction model based on machine learning algorithms such as C4.5, RIPPER, Naïve Bayesian, and AdaBoost and compare their classification accuracy performance. The experiments demonstrate that the RIPPER algorithm, based on accuracy, consistently outperforms the other models in the performance of housing price prediction.



## sample citations

Sample Citation: [@antipov12] [see: @antipov12, pp. 33-35; also @antipov12, ch. 1 and *passim*]

A minus sign (-) before the @ will suppress mention of the author in the citation. This can be useful when the author is already mentioned in the text:

Antipov says blah [-@antipov12].

You can also write an in-text citation, as follows:

@antipov12 says blah.